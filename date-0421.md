## 4月20日

### 今天任务
1. 分析实例，数据去重
2. 分析实例，排序
3. 分析实例，单表关联
4. 分析实例，多表关联

### 遇到的问题
1.  排序实例中，因为不同的节点也需要排序.
	(实际集群中，是对key进行hash,均匀分到不同的partition中，同一key分到相同的partition中)因此在数据进行分节点的时候，partitionID是按照key从小到大分区的

2.  单表关联中，有个巧妙的办法，利用了hadoop自带的shuffle。
	左表以child，child-parent为key和value.
	右表以parent，child-parent为key和value.
	当进行shuffle时，自动将其同一值合并.
	再取其value中的child 和 parent(特殊)做笛卡儿积.
